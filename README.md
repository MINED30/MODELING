# MODELING with papers

<table>
    <thead>
        <tr>
            <th>Index</th>
            <th>Filename</th>
            <th>Description　　　　　　　　　　　　　　　</th>
            <th>Paper</th>
            <th>Related Projects</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=2>1</td>
            <td><a href="https://github.com/MINED30/MODELING/blob/main/Vision_Transformer.ipynb">Vision_Transformer.ipynb</a></td>
            <td>Build Vision Transformer from scratch<br>+use pretrained model</td>
            <td><a href="https://arxiv.org/pdf/2010.11929.pdf">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></td>
            <td>Denoising Images</td>
        </tr>
        <tr>
            <td colspan=4><img src="https://user-images.githubusercontent.com/73981982/139864986-e2822a5b-0a99-48bf-8d6d-3b2beee7024c.png"><br>CIFAR10 : Trainset Accuracy - 67% / Testset Accuracy - 50%</td>
        </tr>
        <tr>
            <td>3</td>
            <td>[-.ipynb](-)</td>
            <td>Apply pretraining methodology to ???</td>
            <td><a href="https://arxiv.org/pdf/1912.08777.pdf">PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization</a></td>
            <td>Get Wings!</td>
        </tr>
        <tr>
            <td>4</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://arxiv.org/pdf/2103.14030.pdf">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></td>
            <td>AI-based X-ray security screening system</td>
        </tr>
        <tr>
            <td>5</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://arxiv.org/pdf/1611.07004.pdf">Image-to-Image Translation with Conditional Adversarial Networks
</a></td>
            <td rowspan=2><a href="https://github.com/MINED30/HAN2HAN">Han2Han</a></td>
        </tr>
        <tr>
            <td>6</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://arxiv.org/pdf/1411.1784.pdf">Conditional Generative Adversarial Nets</a></td>
        </tr>
        <tr>
            <td>7</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a></td>
            <td rowspan=2>Chatbot</td>
        </tr>
        <tr>
            <td>8</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">GPT2</a></td>
        </tr>
        <tr>
            <td>9</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://arxiv.org/pdf/2102.04432.pdf">Colorization Transformer</td>
            <td>Colorization Transformer</td>
        </tr>
        <tr>
            <td>10</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://arxiv.org/pdf/2003.10555.pdf">ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS</a></td>
            <td><a href="https://github.com/MINED30/Hate_Speech_Detection">Hate Speech Detection</a></td>
        </tr>
        <tr>
            <td>11</td>
            <td>[-.ipynb](-)</td>
            <td> </td>
            <td><a href="https://arxiv.org/pdf/1804.02767.pdf">YOLOv3</a></td>
            <td><a href="https://github.com/MINED30/Face_Mask_Detection_YOLO">Face Mask Detection</a></td>
        </tr>
    </tbody>
</table>
